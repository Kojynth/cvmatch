"""
Title Cleaner - Nettoyage des titres "romans" et post-processing.

Supprime les suffixes de dates, coupe les titres trop longs, 
enl√®ve les parenth√®ses/exclamations orphelines, et reclasse
si n√©cessaire selon les tokens significatifs restants.
"""

import re
from typing import Optional, Tuple, List
from dataclasses import dataclass

from ..logging.safe_logger import get_safe_logger
from ..config import DEFAULT_PII_CONFIG
from .feature_flags import get_extraction_fixes_flags
from .intelligent_routing import get_intelligent_router, ContentType

logger = get_safe_logger(__name__, cfg=DEFAULT_PII_CONFIG)


@dataclass
class CleaningResult:
    """R√©sultat du nettoyage d'un titre."""
    original: str
    cleaned: str
    was_truncated: bool
    removed_dates: bool
    removed_punctuation: bool
    significant_tokens: int
    suggested_reclassification: Optional[str] = None
    reason: str = ""


class TitleCleaner:
    """Nettoyeur de titres avec post-processing intelligent."""
    
    def __init__(self):
        self.logger = get_safe_logger(f"{__name__}.TitleCleaner", cfg=DEFAULT_PII_CONFIG)
        self.flags = get_extraction_fixes_flags()
        self.router = get_intelligent_router()
        
        # Patterns pour supprimer les suffixes de dates
        self.date_suffix_patterns = [
            # Dates avec tirets: ‚Äî 09/2022 ‚Äì 10/2022
            r'\s*[‚Äî‚Äì-]\s*\d{1,2}/\d{4}\s*[‚Äî‚Äì-]\s*\d{1,2}/\d{4}\s*$',
            r'\s*[‚Äî‚Äì-]\s*\d{4}\s*[‚Äî‚Äì-]\s*\d{4}\s*$',
            # Dates simples: - 2023, (2022-2023)
            r'\s*[‚Äî‚Äì-]\s*\d{4}\s*$',
            r'\s*[‚Äî‚Äì-]\s*\d{1,2}/\d{4}\s*$',
            # Parenth√®ses avec dates: (09/2022 ‚Äì 10/2022)
            r'\s*\(\d{1,2}/\d{4}\s*[‚Äî‚Äì-]\s*\d{1,2}/\d{4}\)\s*$',
            r'\s*\(\d{4}\s*[‚Äî‚Äì-]\s*\d{4}\)\s*$',
            r'\s*\(\d{4}\)\s*$',
            # Patterns avec "depuis", "√† ce jour"
            r'\s*[‚Äî‚Äì-]\s*depuis\s+\d{4}\s*$',
            r'\s*[‚Äî‚Äì-]\s*√†\s+ce\s+jour\s*$',
            r'\s*[‚Äî‚Äì-]\s*pr√©sent\s*$',
        ]
        
        # Patterns pour nettoyer la ponctuation orpheline
        self.orphan_punctuation_patterns = [
            # Parenth√®ses/crochets non appari√©s
            r'\s*\(\s*$',  # Parenth√®se ouvrante en fin
            r'^\s*\)\s*',  # Parenth√®se fermante en d√©but
            r'\s*\[\s*$',  # Crochet ouvrant en fin
            r'^\s*\]\s*',  # Crochet fermant en d√©but
            # Ponctuation excessive
            r'\s*[,;:]+\s*$',  # Virgules/points-virgules en fin
            r'^\s*[,;:]+\s*',  # Virgules/points-virgules en d√©but
            r'\s*[!?]{2,}\s*$',  # Points d'exclamation multiples
            # Tirets orphelins
            r'^\s*[‚Äî‚Äì-]\s*',  # Tiret en d√©but
            r'\s*[‚Äî‚Äì-]\s*$',  # Tiret en fin (apr√®s nettoyage dates)
        ]
        
        # Mots non-significatifs (stop words)
        self.stop_words = {
            # Fran√ßais
            'le', 'la', 'les', 'un', 'une', 'des', 'du', 'de', 'et', 'ou', '√†', 'en',
            'dans', 'sur', 'avec', 'pour', 'par', 'sans', 'sous', 'chez', 'entre',
            'durant', 'pendant', 'depuis', 'jusqu', 'vers', 'selon', 'contre',
            # Anglais  
            'the', 'a', 'an', 'and', 'or', 'in', 'on', 'at', 'to', 'for', 'of',
            'with', 'by', 'from', 'about', 'into', 'through', 'during', 'before',
            'after', 'above', 'below', 'between', 'among', 'under', 'over',
            # Communs
            'stage', 'internship', 'projet', 'project'
        }
    
    def remove_date_suffixes(self, title: str) -> Tuple[str, bool]:
        """Supprime les suffixes de dates du titre."""
        if not title:
            return title, False
        
        cleaned = title
        removed_any = False
        
        for pattern in self.date_suffix_patterns:
            before_length = len(cleaned)
            cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)
            if len(cleaned) < before_length:
                removed_any = True
        
        return cleaned.strip(), removed_any
    
    def remove_orphan_punctuation(self, title: str) -> Tuple[str, bool]:
        """Enl√®ve la ponctuation orpheline."""
        if not title:
            return title, False
        
        cleaned = title
        removed_any = False
        
        for pattern in self.orphan_punctuation_patterns:
            before_length = len(cleaned)
            cleaned = re.sub(pattern, '', cleaned)
            if len(cleaned) < before_length:
                removed_any = True
        
        return cleaned.strip(), removed_any
    
    def truncate_if_needed(self, title: str, max_length: Optional[int] = None) -> Tuple[str, bool]:
        """Tronque le titre si trop long."""
        if not title:
            return title, False
        
        if max_length is None:
            max_length = self.flags.max_title_length if self.flags.max_title_length > 0 else 120
        
        if len(title) <= max_length:
            return title, False
        
        # Tronquer au dernier espace avant la limite pour √©viter de couper un mot
        truncated = title[:max_length]
        last_space = truncated.rfind(' ')
        
        if last_space > max_length * 0.8:  # Si l'espace est assez proche de la fin
            truncated = truncated[:last_space]
        
        return truncated.strip(), True
    
    def count_significant_tokens(self, title: str) -> int:
        """Compte les tokens significatifs (non stop-words)."""
        if not title:
            return 0
        
        # Tokenizer simple
        tokens = re.findall(r'\b\w{2,}\b', title.lower())
        
        # Filtrer les stop words
        significant = [token for token in tokens if token not in self.stop_words]
        
        return len(significant)
    
    def suggest_reclassification(self, cleaned_title: str, significant_tokens: int) -> Tuple[Optional[str], str]:
        """Sugg√®re une reclassification si le titre nettoy√© est trop court."""
        if significant_tokens >= 3:
            return None, "sufficient_tokens"
        
        # Moins de 3 tokens significatifs - analyser pour reclassification
        if not cleaned_title:
            return "interest", "empty_after_cleaning"
        
        # Utiliser le router intelligent pour d√©terminer le type
        decision = self.router.route_content(cleaned_title)
        
        if decision.target_type == ContentType.PROJECT:
            return "project", f"project_signals_detected: {decision.reason}"
        elif decision.target_type == ContentType.INTEREST:
            return "interest", f"interest_signals_detected: {decision.reason}"
        elif significant_tokens <= 1:
            return "interest", "single_significant_token"
        
        return None, "keep_as_is"
    
    def clean_title(self, title: str, max_length: Optional[int] = None) -> CleaningResult:
        """
        Nettoie compl√®tement un titre avec toutes les √©tapes.
        
        Args:
            title: Titre original √† nettoyer
            max_length: Longueur maximale (d√©faut depuis feature flags)
        
        Returns:
            R√©sultat complet du nettoyage avec suggestions
        """
        if not title:
            return CleaningResult(
                original="",
                cleaned="",
                was_truncated=False,
                removed_dates=False,
                removed_punctuation=False,
                significant_tokens=0,
                reason="empty_input"
            )
        
        original = title
        current = title
        
        # √âtape 1: Supprimer les suffixes de dates
        current, removed_dates = self.remove_date_suffixes(current)
        
        # √âtape 2: Supprimer la ponctuation orpheline 
        current, removed_punctuation = self.remove_orphan_punctuation(current)
        
        # √âtape 3: Tronquer si n√©cessaire
        current, was_truncated = self.truncate_if_needed(current, max_length)
        
        # √âtape 4: Analyser les tokens significatifs
        significant_tokens = self.count_significant_tokens(current)
        
        # √âtape 5: Sugg√©rer reclassification si n√©cessaire
        suggested_reclass, reason = self.suggest_reclassification(current, significant_tokens)
        
        result = CleaningResult(
            original=original,
            cleaned=current,
            was_truncated=was_truncated,
            removed_dates=removed_dates,
            removed_punctuation=removed_punctuation,
            significant_tokens=significant_tokens,
            suggested_reclassification=suggested_reclass,
            reason=reason
        )
        
        # Log si nettoyage significatif
        if any([removed_dates, removed_punctuation, was_truncated, suggested_reclass]):
            self.logger.debug(
                f"TITLE_CLEAN: '{original}' -> '{current}' | "
                f"dates:{removed_dates} punct:{removed_punctuation} trunc:{was_truncated} "
                f"tokens:{significant_tokens} reclass:{suggested_reclass}"
            )
        
        return result
    
    def clean_titles_batch(self, titles: List[str]) -> List[CleaningResult]:
        """Nettoie une liste de titres en batch."""
        return [self.clean_title(title) for title in titles]


# Instance globale
_title_cleaner = None


def get_title_cleaner() -> TitleCleaner:
    """Obtient l'instance globale du nettoyeur de titres."""
    global _title_cleaner
    if _title_cleaner is None:
        _title_cleaner = TitleCleaner()
    return _title_cleaner


def clean_title_simple(title: str, max_length: int = 120) -> str:
    """Fonction de convenance pour nettoyer un titre simplement."""
    cleaner = get_title_cleaner()
    result = cleaner.clean_title(title, max_length)
    return result.cleaned


def should_reclassify_after_cleaning(title: str) -> Tuple[bool, Optional[str]]:
    """D√©termine si un titre doit √™tre reclassifi√© apr√®s nettoyage."""
    cleaner = get_title_cleaner()
    result = cleaner.clean_title(title)
    
    if result.suggested_reclassification:
        return True, result.suggested_reclassification
    
    return False, None


if __name__ == "__main__":
    # Tests du nettoyeur de titres
    cleaner = TitleCleaner()
    
    test_titles = [
        # Titres avec dates
        "D√©veloppeur Web ‚Äî 09/2022 ‚Äì 10/2022",
        "Chef de projet (2020-2023)",
        "Stage chez Google - depuis 2023",
        
        # Titres trop longs
        "Responsable d√©veloppement applications web et mobile avec expertise React, Node.js et gestion d'√©quipe dans environnement Agile et DevOps",
        
        # Ponctuation orpheline
        "D√©veloppeur (",
        ") Consultant IT",
        "Manager, ",
        
        # Titres courts apr√®s nettoyage
        "Stage - 2023",
        "Projet ()",
        "Formation chez √©cole",
        
        # Titres normaux
        "D√©veloppeur Python",
        "Chef de projet IT"
    ]
    
    print("Test du nettoyeur de titres")
    print("=" * 60)
    
    for title in test_titles:
        result = cleaner.clean_title(title)
        
        print(f"Original: '{result.original}'")
        print(f"Nettoy√©:  '{result.cleaned}'")
        print(f"Modifications: dates={result.removed_dates}, punct={result.removed_punctuation}, trunc={result.was_truncated}")
        print(f"Tokens significatifs: {result.significant_tokens}")
        
        if result.suggested_reclassification:
            print(f"üîÑ Reclassification sugg√©r√©e: {result.suggested_reclassification} ({result.reason})")
        
        print("-" * 40)