"""
Parallel Initialization Manager
===============================

Gestionnaire pour parallÃ©liser les initialisations non-critiques.
RÃ©duit le temps de dÃ©marrage en lanÃ§ant plusieurs tÃ¢ches en parallÃ¨le.
"""

import time
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Callable, Dict, Any, Optional, Tuple
from dataclasses import dataclass

# Logger sÃ©curisÃ©
try:
    from ..logging.safe_logger import get_safe_logger
    from ..config import DEFAULT_PII_CONFIG
    logger = get_safe_logger(__name__, cfg=DEFAULT_PII_CONFIG)
except ImportError:
    import logging
    logger = logging.getLogger(__name__)


@dataclass
class InitTask:
    """TÃ¢che d'initialisation."""
    name: str
    func: Callable
    args: tuple = ()
    kwargs: dict = None
    critical: bool = False
    timeout: float = 30.0
    
    def __post_init__(self):
        if self.kwargs is None:
            self.kwargs = {}


@dataclass
class InitResult:
    """RÃ©sultat d'une tÃ¢che d'initialisation."""
    task_name: str
    success: bool
    result: Any = None
    error: Optional[Exception] = None
    duration: float = 0.0


class ParallelInitializer:
    """Gestionnaire d'initialisation parallÃ¨le."""
    
    def __init__(self, max_workers: int = 3):
        self.max_workers = max_workers
        self.tasks: List[InitTask] = []
        self.results: Dict[str, InitResult] = {}
    
    def add_task(self, name: str, func: Callable, *args, critical: bool = False, 
                 timeout: float = 30.0, **kwargs):
        """Ajouter une tÃ¢che d'initialisation."""
        task = InitTask(
            name=name,
            func=func,
            args=args,
            kwargs=kwargs,
            critical=critical,
            timeout=timeout
        )
        self.tasks.append(task)
        logger.debug(f"ðŸ“‹ Added task: {name} (critical={critical})")
    
    def _execute_task(self, task: InitTask) -> InitResult:
        """ExÃ©cuter une tÃ¢che d'initialisation."""
        start_time = time.time()
        
        try:
            logger.debug(f"ðŸ”„ Starting: {task.name}")
            result = task.func(*task.args, **task.kwargs)
            duration = time.time() - start_time
            
            logger.info(f"âœ… Completed: {task.name} ({duration:.2f}s)")
            return InitResult(
                task_name=task.name,
                success=True,
                result=result,
                duration=duration
            )
        
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"âŒ Failed: {task.name} ({duration:.2f}s) - {e}")
            
            return InitResult(
                task_name=task.name,
                success=False,
                error=e,
                duration=duration
            )
    
    def run_sequential(self) -> Dict[str, InitResult]:
        """ExÃ©cuter les tÃ¢ches de maniÃ¨re sÃ©quentielle (pour debug)."""
        logger.info(f"ðŸ”„ Running {len(self.tasks)} tasks sequentially...")
        
        for task in self.tasks:
            result = self._execute_task(task)
            self.results[task.name] = result
            
            # ArrÃªter si une tÃ¢che critique Ã©choue
            if task.critical and not result.success:
                logger.error(f"ðŸ’€ Critical task failed: {task.name}")
                break
        
        return self.results
    
    def run_parallel(self) -> Dict[str, InitResult]:
        """ExÃ©cuter les tÃ¢ches en parallÃ¨le."""
        if not self.tasks:
            return {}
        
        logger.info(f"âš¡ Running {len(self.tasks)} tasks in parallel (max_workers={self.max_workers})...")
        start_time = time.time()
        
        # SÃ©parer les tÃ¢ches critiques et non-critiques
        critical_tasks = [t for t in self.tasks if t.critical]
        non_critical_tasks = [t for t in self.tasks if not t.critical]
        
        # ExÃ©cuter les tÃ¢ches critiques d'abord (sÃ©quentiellement)
        for task in critical_tasks:
            result = self._execute_task(task)
            self.results[task.name] = result
            
            if not result.success:
                logger.error(f"ðŸ’€ Critical task failed: {task.name}")
                return self.results
        
        # ExÃ©cuter les tÃ¢ches non-critiques en parallÃ¨le
        if non_critical_tasks:
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                # Soumettre toutes les tÃ¢ches
                future_to_task = {
                    executor.submit(self._execute_task, task): task
                    for task in non_critical_tasks
                }
                
                # RÃ©cupÃ©rer les rÃ©sultats au fur et Ã  mesure
                for future in as_completed(future_to_task, timeout=60):
                    task = future_to_task[future]
                    
                    try:
                        result = future.result(timeout=task.timeout)
                        self.results[task.name] = result
                    except Exception as e:
                        logger.error(f"âŒ Task {task.name} failed with exception: {e}")
                        self.results[task.name] = InitResult(
                            task_name=task.name,
                            success=False,
                            error=e,
                            duration=0.0
                        )
        
        total_duration = time.time() - start_time
        success_count = sum(1 for r in self.results.values() if r.success)
        
        logger.info(f"âš¡ Parallel init completed: {success_count}/{len(self.tasks)} tasks succeeded in {total_duration:.2f}s")
        
        return self.results
    
    def get_result(self, task_name: str) -> Optional[InitResult]:
        """RÃ©cupÃ©rer le rÃ©sultat d'une tÃ¢che."""
        return self.results.get(task_name)
    
    def get_successful_results(self) -> Dict[str, Any]:
        """RÃ©cupÃ©rer tous les rÃ©sultats rÃ©ussis."""
        return {
            name: result.result 
            for name, result in self.results.items() 
            if result.success
        }
    
    def get_failed_tasks(self) -> List[str]:
        """RÃ©cupÃ©rer les noms des tÃ¢ches qui ont Ã©chouÃ©."""
        return [
            name for name, result in self.results.items() 
            if not result.success
        ]
    
    def print_summary(self):
        """Afficher un rÃ©sumÃ© des rÃ©sultats."""
        if not self.results:
            logger.info("ðŸ“‹ No initialization tasks executed")
            return
        
        total_tasks = len(self.results)
        successful = sum(1 for r in self.results.values() if r.success)
        failed = total_tasks - successful
        total_time = sum(r.duration for r in self.results.values())
        
        logger.info("=" * 50)
        logger.info("ðŸ“Š INITIALIZATION SUMMARY")
        logger.info("=" * 50)
        logger.info(f"âœ… Successful: {successful}/{total_tasks}")
        logger.info(f"âŒ Failed: {failed}/{total_tasks}")
        logger.info(f"â±ï¸ Total time: {total_time:.2f}s")
        
        if failed > 0:
            logger.info("\nâŒ Failed tasks:")
            for name, result in self.results.items():
                if not result.success:
                    logger.error(f"  â€¢ {name}: {result.error}")
        
        logger.info("\nâ±ï¸ Task durations:")
        for name, result in sorted(self.results.items(), key=lambda x: x[1].duration, reverse=True):
            status = "âœ…" if result.success else "âŒ"
            logger.info(f"  â€¢ {status} {name}: {result.duration:.2f}s")
        
        logger.info("=" * 50)


# Fonctions utilitaires pour les tÃ¢ches communes
def init_database():
    """Initialiser la base de donnÃ©es."""
    try:
        from ..models.database import create_db_and_tables
        create_db_and_tables()
        return True
    except Exception as e:
        logger.error(f"Database init failed: {e}")
        return False


def init_logging_handlers():
    """Initialiser les handlers de logging."""
    try:
        import logging
        from logging.handlers import RotatingFileHandler
        from pathlib import Path
        
        # CrÃ©er les dossiers logs
        logs_dir = Path("logs")
        logs_dir.mkdir(exist_ok=True)
        
        return True
    except Exception as e:
        logger.error(f"Logging init failed: {e}")
        return False


def init_user_directories():
    """CrÃ©er les dossiers utilisateur."""
    try:
        import os
        user_dirs = [
            "logs", "CV", "CV/importÃ©s", "CV/gÃ©nÃ©rÃ©s",
            "runtime", "runtime/cache", "runtime/exports"
        ]
        
        for dir_path in user_dirs:
            os.makedirs(dir_path, exist_ok=True)
        
        return len(user_dirs)
    except Exception as e:
        logger.error(f"User directories init failed: {e}")
        return False


def preload_gpu_detection():
    """PrÃ©-charger la dÃ©tection GPU."""
    try:
        from .gpu_utils_optimized import get_gpu_manager
        gpu_manager = get_gpu_manager(use_cache=True)
        return gpu_manager.gpu_info
    except Exception as e:
        logger.error(f"GPU detection failed: {e}")
        return False


def preload_ml_components():
    """PrÃ©-charger les composants ML essentiels."""
    try:
        from .lazy_imports import preload_background
        preload_background()
        return True
    except Exception as e:
        logger.error(f"ML preload failed: {e}")
        return False


# Instance globale pour rÃ©utilisation
_global_initializer = None

def get_global_initializer() -> ParallelInitializer:
    """Obtenir l'instance globale du gestionnaire d'initialisation."""
    global _global_initializer
    if _global_initializer is None:
        _global_initializer = ParallelInitializer()
    return _global_initializer