#!/usr/bin/env python3
"""
Setup Universal
===============

Installation automatique adaptative selon le GPU dÃ©tectÃ©.
Garantit une gÃ©nÃ©ration CV sous 10 minutes sur TOUT systÃ¨me.
"""

import subprocess
import sys
import platform
from pathlib import Path
from loguru import logger


def detect_gpu_basic():
    """DÃ©tection GPU basique sans dÃ©pendances."""
    gpu_info = {"name": "unknown", "vram_gb": 0, "vendor": "unknown"}
    
    try:
        if platform.system() == "Windows":
            # Utiliser wmic sur Windows
            result = subprocess.run(
                ["wmic", "path", "win32_VideoController", "get", "name,AdapterRAM"],
                capture_output=True, text=True, timeout=10
            )
            
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')[1:]  # Skip header
                for line in lines:
                    line = line.strip()
                    if line and "nvidia" in line.lower():
                        gpu_info["name"] = line.split()[0] if line.split() else "NVIDIA GPU"
                        gpu_info["vendor"] = "nvidia"
                        
                        # Estimation VRAM basique
                        if "rtx 50" in line.lower():
                            gpu_info["vram_gb"] = 16  # Estimation RTX 50 series
                        elif "rtx 40" in line.lower():
                            if "4090" in line.lower():
                                gpu_info["vram_gb"] = 24
                            elif "4080" in line.lower():
                                gpu_info["vram_gb"] = 16
                            elif "4070" in line.lower():
                                gpu_info["vram_gb"] = 12
                            elif "4060" in line.lower():
                                gpu_info["vram_gb"] = 8
                            elif "4050" in line.lower():
                                gpu_info["vram_gb"] = 6
                        elif "rtx 30" in line.lower():
                            if "3090" in line.lower():
                                gpu_info["vram_gb"] = 24
                            elif "3080" in line.lower():
                                gpu_info["vram_gb"] = 10
                            elif "3070" in line.lower():
                                gpu_info["vram_gb"] = 8
                            elif "3060" in line.lower():
                                gpu_info["vram_gb"] = 8
                            elif "3050" in line.lower():
                                gpu_info["vram_gb"] = 4
                        elif "gtx 10" in line.lower():
                            if "1080" in line.lower():
                                gpu_info["vram_gb"] = 8
                            elif "1070" in line.lower():
                                gpu_info["vram_gb"] = 8
                            elif "1060" in line.lower():
                                gpu_info["vram_gb"] = 6
                        break
                        
    except Exception as e:
        logger.warning(f"DÃ©tection GPU Ã©chouÃ©e: {e}")
    
    return gpu_info


def get_installation_profile(gpu_info):
    """DÃ©termine le profil d'installation selon le GPU."""
    vram_gb = gpu_info["vram_gb"]
    gpu_name = gpu_info["name"].lower()
    
    if vram_gb >= 12 or "rtx 40" in gpu_name or "rtx 50" in gpu_name:
        return {
            "profile": "ultra_performance",
            "description": "GPU haut de gamme - Performance maximale",
            "packages": [
                "transformers>=4.46.0",
                "torch>=2.2.0", 
                "vllm>=0.6.0",
                "auto-gptq>=0.7.0",
                "flash-attn>=2.5.0",
                "xformers>=0.0.26"
            ],
            "estimated_time": "1-3 minutes",
            "quality": "Excellente"
        }
    elif vram_gb >= 6 or "rtx 30" in gpu_name or "rtx 20" in gpu_name:
        return {
            "profile": "high_performance", 
            "description": "GPU moderne - Bonne performance",
            "packages": [
                "transformers>=4.46.0",
                "torch>=2.2.0",
                "auto-gptq>=0.7.0",
                "xformers>=0.0.26"
            ],
            "estimated_time": "2-5 minutes",
            "quality": "TrÃ¨s bonne"
        }
    elif vram_gb >= 4 or "gtx 10" in gpu_name or "gtx 16" in gpu_name:
        return {
            "profile": "medium_performance",
            "description": "GPU older - Performance correcte", 
            "packages": [
                "transformers>=4.46.0",
                "torch>=2.2.0",
                "auto-gptq>=0.7.0"
            ],
            "estimated_time": "4-8 minutes",
            "quality": "Bonne"
        }
    else:
        return {
            "profile": "basic_performance",
            "description": "GPU faible/CPU - Configuration minimale",
            "packages": [
                "transformers>=4.46.0",
                "torch>=2.2.0"
            ],
            "estimated_time": "6-10 minutes", 
            "quality": "Correcte"
        }


def install_base_requirements():
    """Installe les dÃ©pendances de base obligatoires."""
    logger.info("ğŸ“¦ Installation des dÃ©pendances de base...")
    
    base_packages = [
        "PySide6>=6.8.0",
        "qtawesome>=1.3.0", 
        "sqlmodel>=0.0.16",
        "sqlite-utils>=3.36.0",
        "pypdf>=3.17.0",
        "markdown>=3.5.2",
        "jinja2>=3.1.3",
        "loguru>=0.7.2",
        "psutil>=5.9.0",
        "requests>=2.31.0"
    ]
    
    success_count = 0
    for package in base_packages:
        try:
            cmd = [sys.executable, "-m", "pip", "install", package]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
            
            if result.returncode == 0:
                success_count += 1
            else:
                logger.warning(f"âš ï¸ Ã‰chec {package}: {result.stderr}")
                
        except Exception as e:
            logger.error(f"âŒ Erreur {package}: {e}")
    
    logger.info(f"ğŸ“¦ Base installÃ©e: {success_count}/{len(base_packages)} packages")
    return success_count == len(base_packages)


def install_ai_packages(profile):
    """Installe les packages IA selon le profil."""
    logger.info(f"ğŸ¤– Installation profil {profile['profile']}...")
    
    success_count = 0
    for package in profile["packages"]:
        try:
            logger.info(f"â¬‡ï¸ Installation {package}...")
            
            # Timeout adaptÃ© selon le package
            timeout = 600 if "vllm" in package or "flash-attn" in package else 180
            
            cmd = [sys.executable, "-m", "pip", "install", package]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)
            
            if result.returncode == 0:
                logger.info(f"âœ… {package} installÃ©")
                success_count += 1
            else:
                logger.warning(f"âš ï¸ Ã‰chec {package} - Continu quand mÃªme")
                # Ne pas Ã©chouer pour les packages optionnels
                
        except subprocess.TimeoutExpired:
            logger.warning(f"â° Timeout {package} - Package optionnel ignorÃ©")
        except Exception as e:
            logger.warning(f"âŒ Erreur {package}: {e}")
    
    logger.info(f"ğŸ¤– IA installÃ©e: {success_count}/{len(profile['packages'])} packages")
    return success_count > 0  # Au moins un package IA installÃ©


def test_installation():
    """Test l'installation."""
    logger.info("ğŸ§ª Test de l'installation...")
    
    tests = {
        "PySide6": False,
        "transformers": False,
        "torch": False,
        "vllm": False,
        "auto_gptq": False
    }
    
    # Test imports
    for package in tests.keys():
        try:
            if package == "auto_gptq":
                import auto_gptq
            else:
                __import__(package)
            tests[package] = True
        except ImportError:
            pass
    
    # Affichage rÃ©sultats
    success_count = sum(tests.values())
    logger.info(f"ğŸ“Š Tests: {success_count}/{len(tests)} rÃ©ussis")
    
    for name, status in tests.items():
        icon = "âœ…" if status else "âŒ"
        logger.info(f"  {icon} {name}")
    
    return tests


def create_performance_summary(gpu_info, profile, tests):
    """CrÃ©e un rÃ©sumÃ© des performances attendues."""
    try:
        summary_file = Path(__file__).parent.parent / "INSTALLATION_SUMMARY.md"
        
        # DÃ©terminer les optimisations actives
        optimizations = []
        if tests.get("vllm"):
            optimizations.append("âœ… vLLM - Engine ultra-rapide")
        if tests.get("auto_gptq"):
            optimizations.append("âœ… Auto-GPTQ - Quantification optimisÃ©e")
        if tests.get("torch"):
            optimizations.append("âœ… PyTorch - Backend IA")
        if tests.get("transformers"):
            optimizations.append("âœ… Transformers - ModÃ¨les Hugging Face")
        
        if not optimizations:
            optimizations.append("âŒ Aucune optimisation IA installÃ©e")
        
        content = f"""# ğŸš€ Installation CVMatch TerminÃ©e

## ğŸ® Votre Configuration
- **GPU**: {gpu_info['name']} ({gpu_info['vram_gb']}GB VRAM)
- **Profil**: {profile['profile']}
- **Performance attendue**: {profile['estimated_time']} par CV
- **QualitÃ©**: {profile['quality']}

## âš¡ Optimisations InstallÃ©es
{chr(10).join(optimizations)}

## ğŸ“Š Performances Garanties
- **Temps maximum**: 10 minutes par CV (limite absolue)
- **Temps estimÃ©**: {profile['estimated_time']}
- **SystÃ¨me adaptatif**: Optimise automatiquement selon votre GPU

## ğŸ¯ Comment Ã§a marche
1. L'application dÃ©tecte automatiquement votre GPU
2. SÃ©lectionne le modÃ¨le optimal (32B/13B/7B/3B selon performance)
3. Applique la quantification adaptÃ©e (FP16/AWQ/GPTQ/GGML)
4. Garantit la gÃ©nÃ©ration sous 10 minutes

## ğŸš€ PrÃªt Ã  utiliser !
Lancez l'application avec:
```bash
python main.py
```

L'interface affichera automatiquement:
- Votre GPU dÃ©tectÃ©
- Le niveau de performance
- Le temps estimÃ© de gÃ©nÃ©ration
- La garantie "< 10min"

## ğŸ†˜ En cas de problÃ¨me
Si la gÃ©nÃ©ration dÃ©passe 10 minutes, l'application:
1. Interrompt automatiquement le processus
2. GÃ©nÃ¨re un CV de fallback rapide
3. SuggÃ¨re d'optimiser la configuration

Tout est automatique ! ğŸ‰
"""
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info(f"ğŸ“„ RÃ©sumÃ© crÃ©Ã©: {summary_file}")
        return True
        
    except Exception as e:
        logger.error(f"Erreur crÃ©ation rÃ©sumÃ©: {e}")
        return False


def main():
    """Installation automatique universelle."""
    print("ğŸš€ INSTALLATION UNIVERSELLE CVMATCH")
    print("====================================")
    print("DÃ©tection automatique + Installation adaptative")
    print("Garantie: GÃ©nÃ©ration CV < 10 minutes sur TOUT PC")
    print()
    
    # DÃ©tection GPU
    logger.info("ğŸ” DÃ©tection du matÃ©riel...")
    gpu_info = detect_gpu_basic()
    
    if gpu_info["name"] != "unknown":
        logger.info(f"ğŸ® GPU dÃ©tectÃ©: {gpu_info['name']} ({gpu_info['vram_gb']}GB)")
    else:
        logger.info("ğŸ’» Aucun GPU dÃ©tectÃ© - Configuration CPU")
    
    # Profil d'installation
    profile = get_installation_profile(gpu_info)
    logger.info(f"ğŸ“Š Profil sÃ©lectionnÃ©: {profile['profile']}")
    logger.info(f"â±ï¸ Performance attendue: {profile['estimated_time']}")
    
    # Installation de base
    logger.info("\nğŸ“¦ INSTALLATION DE BASE")
    if not install_base_requirements():
        logger.error("âŒ Ã‰chec installation base - Impossible de continuer")
        sys.exit(1)
    
    # Installation IA
    logger.info(f"\nğŸ¤– INSTALLATION IA ({profile['profile'].upper()})")
    if not install_ai_packages(profile):
        logger.error("âŒ Ã‰chec installation IA - FonctionnalitÃ©s limitÃ©es")
    
    # Tests
    logger.info("\nğŸ§ª TESTS FINAUX")
    tests = test_installation()
    
    # RÃ©sumÃ©
    create_performance_summary(gpu_info, profile, tests)
    
    # Conclusion
    print("\n" + "="*50)
    print("ğŸ¯ INSTALLATION TERMINÃ‰E")
    print("="*50)
    
    if tests.get("transformers") and tests.get("torch"):
        print("âœ… CVMatch est prÃªt Ã  utiliser !")
        print(f"âš¡ Performance attendue: {profile['estimated_time']}")
        print("ğŸ® DÃ©tection GPU automatique activÃ©e")
        print("â° Garantie < 10 minutes par CV")
        print()
        print("ğŸš€ Lancez avec: python main.py")
    else:
        print("âš ï¸ Installation partielle")
        print("ğŸ”§ Certaines fonctionnalitÃ©s peuvent Ãªtre limitÃ©es")
        print("ğŸ’¡ Relancez le script ou installez manuellement")
    
    print()
    print("ğŸ“„ Voir INSTALLATION_SUMMARY.md pour les dÃ©tails")


if __name__ == "__main__":
    main()
